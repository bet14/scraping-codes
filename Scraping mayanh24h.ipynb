{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960772cc-623b-47ee-87c6-b957bf722b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from docx import Document\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893c7d62-eed1-4979-8f89-8d38ba89ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading web page content...\n",
      "Content of page 0 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 1 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 2 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 3 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 4 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 5 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 6 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "Content of page 7 has been successfully downloaded.\n",
      "Parsing HTML content...\n",
      "Extracting URLs\n",
      "URLs have been saved to D:/url_mayanh24h.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "]\n",
    "\n",
    "# URL of the website to scrape\n",
    "url_page = \"https://mayanh24h.com/may-anh-mirrorless-cu.html\"\n",
    "urls_records = []\n",
    "\n",
    "try:\n",
    "    print(\"Loading web page content...\")\n",
    "    for page in range(0, 8):\n",
    "        # Download the content of the web page\n",
    "        if page == 0:\n",
    "            response = requests.get(url_page, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "        else:\n",
    "            response = requests.get(url_page + \"?page=\" + str(page), headers={'User-Agent': random.choice(user_agents_list)})\n",
    "        time.sleep(5)\n",
    "        response.raise_for_status()  # Raise an exception for non-successful status codes\n",
    "        print(\"Content of page \" + str(page) + \" has been successfully downloaded.\")\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        print(\"Parsing HTML content...\")\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extracting URLs from 'a' tags with 'href' attribute\n",
    "        print(\"Extracting URLs\")\n",
    "        urls = [a[\"href\"] for a in soup.find_all(\"a\", href=True)]\n",
    "        # Add the URLs to the urls_records list\n",
    "        urls_records.extend(urls)\n",
    "\n",
    "    # Save urls_records to a CSV file and remove duplicate records\n",
    "    file_path = \"D:/url_mayanh24h.csv\"\n",
    "    unique_urls = list(set(urls_records))  # Remove duplicate URLs\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"URL\"])\n",
    "\n",
    "        for url in unique_urls:\n",
    "            writer.writerow([url])\n",
    "\n",
    "    print(f\"URLs have been saved to {file_path}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error downloading URL:\", e)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc3caf-9154-4ece-9ce1-ba875d397631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu từ file CSV gốc\n",
    "df = pd.read_csv('url_text_mayanh.csv')\n",
    "\n",
    "# Lọc các dòng có URL có https và chứa từ khóa canon, sony, fujifilm, olympus, panasonic, leica hoặc nikon\n",
    "filtered_df = df[df['URL'].str.contains('https') & \n",
    "                 (df['URL'].str.contains('canon', case=False) |\n",
    "                  df['URL'].str.contains('sony', case=False) |\n",
    "                  df['URL'].str.contains('fujifilm', case=False) |\n",
    "                  df['URL'].str.contains('olympus', case=False) |\n",
    "                  df['URL'].str.contains('panasonic', case=False) |\n",
    "                  df['URL'].str.contains('leica', case=False) |\n",
    "                  df['URL'].str.contains('nikon', case=False))]\n",
    "\n",
    "# Ghi dữ liệu đã lọc vào file mới\n",
    "filtered_df.to_csv('D:/url_mayanh24h_updated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "222412f1-2e13-4fa4-af79-b6fc1ad06ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải nội dung trang web...\n",
      "Nội dung trang web đã được tải thành công.\n",
      "Phân tích HTML content...\n",
      "Không tìm thấy giá thị trường.\n",
      "                              Title       Price Market Price      Status  \\\n",
      "0  Fujifilm X100, Mới 95% (Màu Bạc)  8.900.000đ          N/A  8.900.000đ   \n",
      "\n",
      "                                             Summary  \n",
      "0  - Bộ vi xử lý: Fujifilm EXR\\n- Cảm biến ảnh: C...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "]\n",
    "\n",
    "# URL của trang web cần scrap\n",
    "url = \"https://mayanh24h.com/fujifilm-x100.html\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Tải nội dung của trang web\n",
    "    print(\"Đang tải nội dung trang web...\")\n",
    "    response = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "    response.raise_for_status()  # Ném ngoại lệ cho các mã trạng thái không tốt\n",
    "    print(\"Nội dung trang web đã được tải thành công.\")\n",
    "\n",
    "    # Phân tích HTML content\n",
    "    print(\"Phân tích HTML content...\")\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Scrap các giá trị từ trang web\n",
    "    title = soup.find(\"h3\", class_=\"text_1 mb-1\")\n",
    "    if title:\n",
    "        title = title.text\n",
    "    else:\n",
    "        title = \"N/A\"\n",
    "        print(\"Không tìm thấy tiêu đề.\")\n",
    "\n",
    "    price = soup.find(\"h2\", class_=\"text-primary font-weight-bold my-2\")\n",
    "    if price:\n",
    "        price = price.text\n",
    "    else:\n",
    "        price = \"N/A\"\n",
    "        print(\"Không tìm thấy giá.\")\n",
    "\n",
    "    market_price = soup.find(\"div\", class_=\"text-secondary pb-1 d-none d-md-block\")\n",
    "    if market_price:\n",
    "        market_price = market_price.text\n",
    "    else:\n",
    "        market_price = \"N/A\"\n",
    "        print(\"Không tìm thấy giá thị trường.\")\n",
    "\n",
    "    status = soup.find(\"span\", class_=\"text-primary\")\n",
    "    if status:\n",
    "        status = status.text\n",
    "    else:\n",
    "        status = \"N/A\"\n",
    "        print(\"Không tìm thấy tình trạng.\")\n",
    "\n",
    "    summary = soup.find(\"div\", class_=\"font-sm block-summary\")\n",
    "    if summary:\n",
    "        summary = summary.text\n",
    "    else:\n",
    "        summary = \"N/A\"\n",
    "        print(\"Không tìm thấy tóm tắt.\")\n",
    "\n",
    "    # Tạo DataFrame từ các giá trị scrap được\n",
    "    data = {\n",
    "        'Title': [title],\n",
    "        'Price': [price],\n",
    "        'Market Price': [market_price],\n",
    "        'Status': [status],\n",
    "        'Summary': [summary]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # In ra DataFrame\n",
    "    print(df)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error downloading URL:\", e)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5974f5e-569a-4dfb-9fc7-a165df6dd9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-m5.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r10-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r50-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r5-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r6-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r6-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-eos-r7-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-g1-x-mark-iii.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-m200-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-m50-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/canon-m50-mark-ii-mau-trang-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-gfx-50s.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x100.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x100f-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x100f-mau-den.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x100t-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x100v-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a20.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a2-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a2-mau-hong.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a3.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a3-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a5-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a5-mau-nau-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a7-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-a7-mau-xanh-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-e2s.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-e3-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-e4-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-h1-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-h2-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-h2s-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-m1-mau-nau-hang-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-pro1.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-s10-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-xs20-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t100-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t10-body-mau-bac.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t1-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t1-graphite-silver-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t20.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t200-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t2-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t2-mau-bac.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t30-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t3-body-mau-bac.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t3-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t4-black-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t4-silver-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/fujifilm-x-t5-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/leica-x-typ-113-black.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/may-anh-canon-mirrorless-cu.html\n",
      "Không tìm thấy tiêu đề.\n",
      "Không tìm thấy giá.\n",
      "Không tìm thấy giá thị trường.\n",
      "Không tìm thấy tóm tắt.\n",
      "An error occurred for URL https://mayanh24h.com/may-anh-canon-mirrorless-cu.html: 'NoneType' object has no attribute 'text'\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/may-anh-fujifilm-cu.html\n",
      "Không tìm thấy tiêu đề.\n",
      "Không tìm thấy giá.\n",
      "Không tìm thấy giá thị trường.\n",
      "Không tìm thấy tóm tắt.\n",
      "An error occurred for URL https://mayanh24h.com/may-anh-fujifilm-cu.html: 'NoneType' object has no attribute 'text'\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/may-anh-fujifilm-x-a10-kit-xc16-50mm-f3-5-5-6-ois-ii-hong.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/may-anh-leica-x1.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/may-anh-panasonic-gh5-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/nikon-z5-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/nikon-z6-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/olympus-omd-e-m5.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/olympus-om-d-e-m5-body-white.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-fz1000.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-fz2500.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-lumix-dmc-g7-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-lumix-gh4-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-lumix-gx80-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/panasonic-lumix-s1r.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a5100-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6000-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6000-mau-den.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6000-mau-trang-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6100-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6300-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6400-hang-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6400-mau-bac-cu.html\n",
      "Không tìm thấy giá thị trường.\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6500-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6600-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a6700-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7-mark-iv-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-mark-iii-a-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-mark-iii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-mark-iv-a-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7r-mark-iv-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-a7s-mark-iii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-7r-mark-v-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-a55-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-a57.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-a7-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-a7-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-alpha-a7s-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-cybershot-dsc-hx200v.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-dsc-h400-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-dsc-rx100.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-fx-30-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-fx3-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-nex-3n-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-nex-5r-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-nex-5t.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-nex-6-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-nex-7-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-qx1.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx0-mark-ii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx100-mark-v.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx-100-mark-vi-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx100-vii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx10-mark-iii-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-rx10-mark-iv.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-zv-1-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-zv-1f-cu.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-zv-e10-mau-den.html\n",
      "Đang tải nội dung trang web: https://mayanh24h.com/sony-zv-e10-mau-trang-cu.html\n",
      "Dữ liệu đã được lưu vào file: D:/dulieu_mayanh.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "]\n",
    "\n",
    "# Đọc file CSV chứa danh sách URL đã cập nhật\n",
    "updated_url_file = \"D:/url_mayanh24h_updated.csv\"\n",
    "\n",
    "try:\n",
    "    # Đọc file CSV\n",
    "    df_urls = pd.read_csv(updated_url_file)\n",
    "\n",
    "    # Tạo một danh sách để chứa dữ liệu từ mỗi URL\n",
    "    data_list = []\n",
    "\n",
    "    # Lặp qua mỗi URL trong dataframe\n",
    "    for index, row in df_urls.iterrows():\n",
    "        url = row['URL']\n",
    "        \n",
    "        try:\n",
    "            # Tải nội dung của trang web\n",
    "            print(\"Đang tải nội dung trang web:\", url)\n",
    "            response = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "            response.raise_for_status()  # Ném ngoại lệ cho các mã trạng thái không tốt\n",
    "\n",
    "            # Phân tích HTML content\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            \n",
    "            # Scrap các giá trị từ trang web\n",
    "\n",
    "            # Scrap các giá trị từ trang web\n",
    "            title = soup.find(\"h3\", class_=\"text_1 mb-1\")\n",
    "            if title:\n",
    "                title = title.text\n",
    "            else:\n",
    "                title = \"N/A\"\n",
    "                print(\"Không tìm thấy tiêu đề.\")\n",
    "        \n",
    "            price = soup.find(\"h2\", class_=\"text-primary font-weight-bold my-2\")\n",
    "            if price:\n",
    "                price = price.text\n",
    "            else:\n",
    "                price = \"N/A\"\n",
    "                print(\"Không tìm thấy giá.\")\n",
    "        \n",
    "            market_price = soup.find(\"div\", class_=\"text-secondary pb-1 d-none d-md-block\")\n",
    "            if market_price:\n",
    "                market_price = market_price.text\n",
    "            else:\n",
    "                market_price = \"N/A\"\n",
    "                print(\"Không tìm thấy giá thị trường.\")\n",
    "        \n",
    "            status = soup.find(\"span\", class_=\"text-primary\")\n",
    "            if status:\n",
    "                status = status.text\n",
    "            else:\n",
    "                status = \"N/A\"\n",
    "                print(\"Không tìm thấy tình trạng.\")\n",
    "        \n",
    "            summary = soup.find(\"div\", class_=\"font-sm block-summary\")\n",
    "            if summary:\n",
    "                summary = summary.text\n",
    "            else:\n",
    "                summary = \"N/A\"\n",
    "                print(\"Không tìm thấy tóm tắt.\")\n",
    "\n",
    "\n",
    "            parent_div = soup.find(\"div\", class_=\"col-12 col-md-8 d-flex d-md-block justify-content-between\")\n",
    "            if parent_div:\n",
    "                # Tìm tất cả các phần tử con\n",
    "                sub_divs = parent_div.find_all(\"div\", class_=\"pb-1\")\n",
    "                \n",
    "                # Kiểm tra xem có đủ số lượng phần tử con hay không\n",
    "                if len(sub_divs) >= 2:\n",
    "                    # Lấy dữ liệu từ div đầu tiên cho status\n",
    "                    brand = sub_divs[0].text.strip()\n",
    "                    \n",
    "                    # Lấy dữ liệu từ div thứ hai cho brand\n",
    "                    status = sub_divs[1].text.strip()\n",
    "                else:\n",
    "                    brand = \"N/A\"\n",
    "                    status = \"N/A\"\n",
    "\n",
    "            summary = soup.find(\"div\", class_=\"font-sm block-summary\").text\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # Thêm dữ liệu vào danh sách\n",
    "            data_list.append({\n",
    "                'Title': title,\n",
    "                'Price': price,\n",
    "                'Market Price': market_price,\n",
    "                'Status': status,\n",
    "                'Brand': brand,\n",
    "                'Summary': summary\n",
    "            })\n",
    "            random_sleep_time = random.randint(3, 12)\n",
    "            time.sleep(random_sleep_time)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading URL {url}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for URL {url}: {e}\")\n",
    "            continue  # Bỏ qua URL hiện tại và tiếp tục với URL tiếp theo\n",
    "\n",
    "    # Tạo DataFrame từ danh sách dữ liệu\n",
    "    df_data = pd.DataFrame(data_list)\n",
    "\n",
    "    # Lưu dataframe thành file CSV\n",
    "    output_csv_file = \"D:/dulieu_mayanh.csv\"\n",
    "    df_data.to_csv(output_csv_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"Dữ liệu đã được lưu vào file:\", output_csv_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {updated_url_file}\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1dc5b3b-f731-4106-86ee-bcef96ffa498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được xử lý và lưu thành công vào file: D:/processed_dulieu_mayanh.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Đọc file CSV\n",
    "input_csv_file = \"D:/dulieu_mayanh.csv\"\n",
    "output_csv_file = \"D:/processed_dulieu_mayanh.csv\"\n",
    "\n",
    "try:\n",
    "    # Đọc file CSV vào DataFrame\n",
    "    df = pd.read_csv(input_csv_file)\n",
    "\n",
    "    # Thực hiện các thay đổi và xử lý\n",
    "    # Replace \"Giá thị trường: \" bằng \"\"\n",
    "    df['Market Price'] = df['Market Price'].str.replace('Giá thị trường: ', '', case=False, regex=True)\n",
    "\n",
    "    # Replace \"đ\" trong Market Price và Price thành \"\"\n",
    "    df['Market Price'] = df['Market Price'].str.replace('đ', '', case=False, regex=True)\n",
    "    #df['Market Price'] = df['Market Price'].str.replace('.', '', case=False, regex=True)\n",
    "    \n",
    "    df['Price'] = df['Price'].str.replace('đ', '', case=False, regex=True)\n",
    "    #df['Price'] = df['Price'].str.replace('.', '', case=False, regex=True)\n",
    "\n",
    "    df['Status'] = df['Status'].str.replace('Tình trạng: ', '', case=False, regex=True)\n",
    "    df['Brand'] = df['Brand'].str.replace('Thương hiệu: ', '', case=False, regex=True)\n",
    "    df['Summary'] = df['Summary'].str.replace(r'(\\d+)\\.(\\d+)', lambda x: x.group(1) + x.group(2), regex=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Tạo cột mới và xử lý summary\n",
    "    df['Định dạng'] = df['Summary'].str.extract(r'(định dạng: [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "    df['Độ phân giải'] = df['Summary'].str.extract(r'(độ phân giải [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "    df['4k'] = df['Summary'].str.extract(r'(4k [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "    # Tạo cột mới và xử lý title\n",
    "    df['Mức độ'] = df['Title'].str.extract(r'([\\d]+)%', expand=False)\n",
    "    df['Đã chụp'] = df['Title'].str.extract(r'([\\w\\s]+) shot', expand=False)\n",
    "    df['Body'] = df['Title'].apply(lambda x: 'Yes' if 'body' in x.lower() else 'No')\n",
    "    df['Kích thước'] = df['Summary'].str.extract(r'(kích thước [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "    df['Trọng lượng'] = df['Summary'].str.extract(r'(Trọng lượng [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "    df['Quay phim'] = df['Summary'].str.extract(r'(Quay phim [\\w\\s]+)', flags=re.IGNORECASE, expand=False)\n",
    "    df['Megapixel'] = df['Summary'].str.contains(r'megapixel|MP', case=False, regex=True)\n",
    "    # Lưu DataFrame vào file CSV mới\n",
    "    df.to_csv(output_csv_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"Dữ liệu đã được xử lý và lưu thành công vào file:\", output_csv_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {input_csv_file}\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602da4f-81dd-4de0-8e4d-c8bfd19be44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
